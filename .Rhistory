packrat::disable()
??set_names()
library(tidyverse)
devtools::document()
devtools::document()
#' Get a list of NHS colour hex codes
#' source: https://www.england.nhs.uk/nhsidentity/identity-guidelines/colours/
#'
#' @export
#'
get_nhs_colours = function() {
list(
# Level 1: NHS blues
nhs_blue = "#005EB8",
nhs_blue_bright = "#0072CE",
nhs_blue_dark = "#003087",
nhs_blue_light = "#41B6E6",
nhs_blue_aqua = "#00A9CE",
# Level 2: NHS neutrals
nhs_black = "#231f20",
nhs_grey_dark = "#425563",
nhs_grey_mid = "#768692",
nhs_grey_pale = "#E8EDEE",
# Level 3: NHS support greens
nhs_green = "#009639",
nhs_green_light = "#78BE20",
nhs_green_dark = "#006747",
nhs_green_aqua = "#00A499",
# Level 4: NHS highlights
nhs_purple = "#330072",
nhs_pink = "#AE2573",
nhs_pink_dark = "#7C2855",
nhs_red_dark = "#8A1538",
nhs_red_emergency = "#DA291C",
nhs_orange = "#ED8B00",
nhs_yellow = "#FAE100",
nhs_yellow_warm = "#FFB81C",
nhs_yellow_ambulance = "#f1dd38"  # hex code from: https://www.ralcolorchart.com/ral-classic/ral-1016-sulfur-yellow
)
}
nhs_cols = get_nhs_colours()
nhs_cols$nhs_blue
nhs_cols$nhs_grey_pale
#' Get a list of NHS colour hex codes
#' source: https://www.england.nhs.uk/nhsidentity/identity-guidelines/colours/
#'
#' @export
#'
get_nhs_colours = function() {
list(
# Level 1: NHS blues
blue = "#005EB8",
blue_bright = "#0072CE",
blue_dark = "#003087",
blue_light = "#41B6E6",
blue_aqua = "#00A9CE",
# Level 2: NHS neutrals
black = "#231f20",
grey_dark = "#425563",
grey_mid = "#768692",
grey_pale = "#E8EDEE",
# Level 3: NHS support greens
green = "#009639",
green_light = "#78BE20",
green_dark = "#006747",
green_aqua = "#00A499",
# Level 4: NHS highlights
purple = "#330072",
pink = "#AE2573",
pink_dark = "#7C2855",
red_dark = "#8A1538",
red_emergency = "#DA291C",
orange = "#ED8B00",
yellow = "#FAE100",
yellow_warm = "#FFB81C",
yellow_ambulance = "#f1dd38"  # hex code from: https://www.ralcolorchart.com/ral-classic/ral-1016-sulfur-yellow
)
}
nhs_cols = get_nhs_colours()
nhs_cols$blue_light
#' Get a list of British Red Cross colour hex codes
#'
#' @export
#'
get_brc_colours = function() {
list(
# these colours are from the Website and SEO guidelines
red = "#D0021B",
red_dark = "#AD1220",
red_light = "#CC434F",
black = "#262626",
grey = "#5C747A",
grey_light = "#9CAAAE",
green = "#40A22A",
green_dark = "#05853A",
green_light = "#44A46C",
blue = "#193351",
blue_light = "#475C74",
teal = "#2B7586",
teal_light = "#6A9EAA"
)
}
cols = get_brc_colours()
cols$grey_light
#' Regular expression to match postcodes (allowing lowercase and unlimited spaces)
#' source: https://stackoverflow.com/a/7259020
#' see also: page 6 of https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/488478/Bulk_Data_Transfer_-_additional_validation_valid_from_12_November_2015.pdf
#'
#' @export
#'
postcode_regex = function() {
"(([gG][iI][rR] {0,}0[aA]{2})|((([a-pr-uwyzA-PR-UWYZ][a-hk-yA-HK-Y]?[0-9][0-9]?)|(([a-pr-uwyzA-PR-UWYZ][0-9][a-hjkstuwA-HJKSTUW])|([a-pr-uwyzA-PR-UWYZ][a-hk-yA-HK-Y][0-9][abehmnprv-yABEHMNPRV-Y]))) {0,}[0-9][abd-hjlnp-uw-zABD-HJLNP-UW-Z]{2}))"
}
postcode_regex()
options("brclib.data_path")
options()
options("width")
file.exists(channel_file)
##
## file and folder names
##
#data.dir = "P:/Operations/Innovation & Insight/Insight/Data science/Data"
data.dir = "C:/Users/040026704/Documents/Data science/Data"
vols.dir = "Volunteers"
# vols.file.in = "20191002 CRV database.xlsx"
# vols.file.out = "CRVs - 05-09-2019.csv"
vols.file.latest = "CRVs - latest.csv"
# pick the most recent .xlsx file in the Volunteers folder
# source: https://stackoverflow.com/questions/13762224/how-to-sort-files-list-by-date/13762544
vols.file.in = file.info(list.files(path = file.path(data.dir, vols.dir), pattern = "*CRV*xlsx", full.names = T)) %>%
rownames_to_column() %>%
mutate(mtime = as.POSIXct(mtime)) %>%
arrange(desc(mtime)) %>%
top_n(1, mtime) %>%
select(rowname) %>%
str_extract(., "[0-9]+ [A-Za-z\\s]*\\.xlsx")  # keep only the filename
list.files(path = file.path(data.dir, vols.dir), pattern = "*CRV*xlsx", full.names = T)
list.files(path = file.path(data.dir, vols.dir), pattern = "*xlsx", full.names = T)
list.files(path = file.path(data.dir, vols.dir), pattern = "*CRV.*xlsx", full.names = T)
# pick the most recent .xlsx file in the Volunteers folder
# source: https://stackoverflow.com/questions/13762224/how-to-sort-files-list-by-date/13762544
vols.file.in = file.info(list.files(path = file.path(data.dir, vols.dir), pattern = "*CRV.*xlsx", full.names = T)) %>%
rownames_to_column() %>%
mutate(mtime = as.POSIXct(mtime)) %>%
arrange(desc(mtime)) %>%
top_n(1, mtime) %>%
select(rowname) %>%
str_extract(., "[0-9]+ [A-Za-z\\s]*\\.xlsx")  # keep only the filename
vols.file.in
# pick the most recent .xlsx file in the Volunteers folder
# source: https://stackoverflow.com/questions/13762224/how-to-sort-files-list-by-date/13762544
vols.file.in = file.info(list.files(path = file.path(data.dir, vols.dir), pattern = "*CRV.*xlsx", full.names = T)) %>%
tibble::rownames_to_column() %>%
dplyr::mutate(mtime = as.POSIXct(mtime)) %>%
dplyr::arrange(dplyr::desc(mtime)) %>%
dplyr::top_n(1, mtime) %>%
dplyr::select(rowname) %>%
stringr::str_extract(., "[0-9]+ [A-Za-z\\s]*\\.xlsx")  # keep only the filename
vols.file.in
options("brclib.data_path")
options("brclib.data_path") = "../../../Data/"
##
## Sets options for this package (currently just `brclib.data_path`)
##
brclib_default_options <- list(
brclib.data_path = "C:/Users/040026704/Documents/Data science/Data"
)
brclib_default_options
op <- options()
toset <- !(names(brclib_default_options) %in% names(op))
toset
if (any(toset)) options(brclib_default_options[toset])
invisible()
options
options()
options("brclib.data_path")
file.path(options("brclib.data_path"), "Volunteers")
vols.dir = file.path(options("brclib.data_path"), "Volunteers")
#' Clean and process Community Reserve Volunteers data
#'
#'
#' @export
#'
process_CRVs = function(vols.dir = file.path(options("brclib.data_path"), "Volunteers"),
vols.file.latest = "CRVs - latest.csv"  # output filename
) {
# pick the most recent .xlsx file in the Volunteers folder
# source: https://stackoverflow.com/questions/13762224/how-to-sort-files-list-by-date/13762544
vols.file.in = file.info(list.files(path = vols.dir, pattern = "*CRV.*xlsx", full.names = T)) %>%
tibble::rownames_to_column() %>%
dplyr::mutate(mtime = as.POSIXct(mtime)) %>%
dplyr::arrange(dplyr::desc(mtime)) %>%
dplyr::top_n(1, mtime) %>%
dplyr::select(rowname) %>%
stringr::str_extract(., "[0-9]+ [A-Za-z\\s]*\\.xlsx")  # keep only the filename
# extract date from filename to make output filename
vols.file.out = paste0("CRVs - ", stringr::str_extract(vols.file.in, "[0-9]+"), ".csv")
# Load CRV data
vols = read_excel(file.path(data.dir, vols.dir, vols.file.in)) %>%
rename(Postcode = postcode) %>%
mutate(Postcode = toupper(Postcode))
################################################################
## merge in coords for postcodes
##
postcodes = read_csv(file.path(data.dir, "Postcodes", "National_Statistics_Postcode_Lookup - BRC.csv"),
col_types = cols(
Postcode = col_character(),
Longitude = col_double(),
Latitude = col_double(),
Country = col_character(),
`Output Area` = col_character(),
LSOA = col_character(),
`Local Authority Code` = col_character(),
`Rural or Urban?` = col_character(),
`Rural Urban classification` = col_character(),
IMD = col_integer(),
IMD.Decile = col_integer(),
IMD.Decile.Name = col_character(),
`Rurality index` = col_double()
))
# the ONS data truncates 7-character postcodes to remove spaces (e.g. CM99 1AB --> CM991AB); get rid of all spaces in both datasets to allow merging
postcodes$Postcode2 = gsub(" ", "", postcodes$Postcode)
vols$Postcode2 = gsub(" ", "", vols$Postcode)
##
## look up and save Jersey, Guernsey and Isle of Man postcode coordinates from https://checkmypostcode.uk/
##
# get subset of Channel Islands + IoM postcodes
channel_new = vols %>%
select(Postcode2) %>%
filter(startsWith(Postcode2, "GY") | startsWith(Postcode2, "JE") | startsWith(Postcode2, "IM")) %>%
distinct()
# lookup
channel = lookup_islands_postcodes(channel_new$Postcode2)
# merge in Channel Island postcodes
postcodes = postcodes %>%
left_join(channel, by = "Postcode2") %>%
mutate(Longitude = ifelse(Longitude.x == 0, Longitude.y, Longitude.x),
Latitude  = ifelse(round(Latitude.x, 0) == 100, Latitude.y, Latitude.x)) %>%
select(-Longitude.x, -Longitude.y, -Latitude.x, -Latitude.y) %>%
replace_na(list(Latitude = 100, Longitude = 0))
##
## merge all postcodes
##
# merge
vols = vols %>%
left_join(postcodes, by="Postcode2")
vols$Postcode2 = NULL  # don't need the truncated column anymore
vols$Postcode.y = NULL
vols = rename(vols, Postcode = Postcode.x)
################################################################
## infer probability of gender from name
##
# get year of birth
vols$year_of_birth = year(vols$date_of_birth)
# get year of joining - round up, but put a ceiling on 2010
vols$recruit_rnd = ifelse(vols$`User Registered` < 2010, roundUp(vols$`User Registered`), 2010)
# need to rename name column to remove space and remove all non graphical characters
# (adapted from https://stackoverflow.com/a/22794831)
vols = vols %>%
mutate(vol_name = str_replace_all(`First Name`, "[^[:graph:]]", " "))
# calculate gender probabilities
tryCatch({
vols_gender = gender_df(vols, name_col="vol_name", year_col=c("year_of_birth", "recruit_rnd"), method="ssa")
# copy genders back into main vols dataframe
vols = vols %>%
left_join(vols_gender, by=c("vol_name" = "name", "year_of_birth" = "year_min", "recruit_rnd" = "year_max"))
# replace NAs with 'Unknown'
vols = vols %>%
mutate(gender = ifelse(is.na(gender), "unknown", gender))
rm(vols_gender)
})
##
## Save
##
vols = vols %>%
select(-`First Name`, -`Last Name`, -`User Email`, -mobile_number, -date_of_birth, -medical_conditions, -emergency_contact_name, -emergency_contact_relationship, -emergency_contact_number)
write_csv(vols, file.path(data.dir, vols.dir, vols.file.out))
write_csv(vols, file.path(data.dir, vols.dir, vols.file.latest))  # save version saying 'latest'
print("Finished cleaning and processing CRVs")
}
vols.file.latest = "CRVs - latest.csv"  # output filename
# pick the most recent CRV .xlsx file in the Volunteers folder
# source: https://stackoverflow.com/questions/13762224/how-to-sort-files-list-by-date/13762544
vols.file.in = file.info(list.files(path = vols.dir, pattern = "*CRV.*xlsx", full.names = T)) %>%
tibble::rownames_to_column() %>%
dplyr::mutate(mtime = as.POSIXct(mtime)) %>%
dplyr::arrange(dplyr::desc(mtime)) %>%
dplyr::top_n(1, mtime) %>%
dplyr::select(rowname) %>%
stringr::str_extract(., "[0-9]+ [A-Za-z\\s]*\\.xlsx")  # keep only the filename
# extract date from filename to make output filename
vols.file.out = paste0("CRVs - ", stringr::str_extract(vols.file.in, "[0-9]+"), ".csv")
vols.file.out
# Load CRV data
vols = readr::read_excel(file.path(vols.dir, vols.file.in)) %>%
dplyr::rename(Postcode = postcode) %>%
dplyr::mutate(Postcode = toupper(Postcode))
# Load CRV data
vols = readxl::read_excel(file.path(vols.dir, vols.file.in)) %>%
dplyr::rename(Postcode = postcode) %>%
dplyr::mutate(Postcode = toupper(Postcode))
vols
##
## merge in coords for postcodes
##
if (!exists("postcodes")) postcodes = load_postcodes()
#' @param postcode.path Where the postcodes file is stored
#' @param postcode.name Name of the postcodes file
#'
#' @example
#' \dontrun{
#' if (!exists("postcodes")) postcodes = load_postcodes()
#' }
#'
#' @export
#'
load_postcodes = function(postcode.path = file.path(options("brclib.data_path"), "Postcodes"),
postcode.name = "National_Statistics_Postcode_Lookup - BRC.csv") {
readr::read_csv(file.path(postcode.path, postcode.name),
col_types = readr::cols(
Postcode = readr::col_character(),
Longitude = readr::col_double(),
Latitude = readr::col_double(),
Country = readr::col_character(),
CountryName = readr::col_character(),
`Output Area` = readr::col_character(),
LSOA = readr::col_character(),
`Local Authority Code` = readr::col_character(),
`Primary Care Trust` = readr::col_character(),
`Rural or Urban?` = readr::col_character(),
`Rural Urban classification` = readr::col_character(),
IMD = readr::col_integer(),
IMD.Decile = readr::col_integer(),
IMD.Decile.Name = readr::col_character(),
`Rurality index` = readr::col_double()
))
}
##
## merge in coords for postcodes
##
if (!exists("postcodes")) postcodes = load_postcodes()
# the ONS data truncates 7-character postcodes to remove spaces (e.g. CM99 1AB --> CM991AB); get rid of all spaces in both datasets to allow merging
postcodes$Postcode2 = gsub(" ", "", postcodes$Postcode)
vols$Postcode2 = gsub(" ", "", vols$Postcode)
##
## look up and save Jersey, Guernsey and Isle of Man postcode coordinates from https://checkmypostcode.uk/
##
# get subset of Channel Islands + IoM postcodes
channel_new = vols %>%
select(Postcode2) %>%
filter(startsWith(Postcode2, "GY") | startsWith(Postcode2, "JE") | startsWith(Postcode2, "IM")) %>%
distinct()
#' Lookup coordinates for UK postcodes that aren't in the ONS postcode directory (tends to be Guernsey, Jersey and Isle of Man), scraping them from https://checkmypostcode.uk/ where necessary.
#' This function also saves the postcodes and coordinates into `islands_file` to prevent needless re-scraping in future.
#'
#' @param islands_postcodes A vector of postcodes to lookup. Note that these shouldn't contain spaces.
#' @param islands_path Folder where the `islands_file` is stored
#' @param islands_file Filename for where to store the postcodes and coordinates.
#' @return A data_frame containing postcodes and coordinates.
#'
#' @export
#'
lookup_islands_postcodes = function(islands_postcodes,
islands_path = options("brclib.data_path"),
islands_file = "UK Islands postcodes.csv") {
channel_file = file.path(islands_path, islands_file)
# track existing postcodes already scraped
existing_pc = c()
# load Islands postcodes we previously stored (if it exists)
if (file.exists(channel_file)) {
channel = readr::read_csv(channel_file)
existing_pc = channel$Postcode2
}
# get rid of spaces (just in case not already done)
islands_postcodes = gsub(" ", "", islands_postcodes)
# get postcodes not in our current list
channel_new = tibble::tibble(
Postcode2 = islands_postcodes[!islands_postcodes %in% existing_pc],  # filter out postcodes we've looked up in the past
Longitude = 0.0,
Latitude = 0.0
)
# set user agent
ua = httr::user_agent("https://redcross.org.uk")
# scrape coordinates for each postcode
if (nrow(channel_new) > 0) {  #... only if there are new postcodes to scrape
print("Scraping new postcodes...")
for (i in 1:nrow(channel_new)) {
pc = channel_new$Postcode2[i]
# get webpage data
req = httr::GET(paste0("https://checkmypostcode.uk/", pc), ua)
# load html
out = httr::content(req, "text")
doc = xml2::read_html(out)
# get list of coordinates
coords = doc %>%
rvest::html_nodes(".small") %>%
rvest::html_text()
lat = as.numeric(stringr::str_extract(coords[1], "-?[0-9]+\\.[0-9]+"))
lon = as.numeric(stringr::str_extract(coords[2], "-?[0-9]+\\.[0-9]+"))
channel_new$Longitude[i] = lon
channel_new$Latitude[i]  = lat
Sys.sleep(0.75)  # scrape responsibly
}
} else {
print("No new postcodes to scrape")
}
# add new postcodes and save
if (exists("channel")) {
channel = dplyr::bind_rows(channel, channel_new)
} else {
channel = channel_new
}
readr::write_csv(channel, channel_file)
channel  # return the postcodes
}
# lookup
channel = lookup_islands_postcodes(channel_new$Postcode2)
#' Lookup coordinates for UK postcodes that aren't in the ONS postcode directory (tends to be Guernsey, Jersey and Isle of Man), scraping them from https://checkmypostcode.uk/ where necessary.
#' This function also saves the postcodes and coordinates into `islands_file` to prevent needless re-scraping in future.
#'
#' @param islands_postcodes A vector of postcodes to lookup. Note that these shouldn't contain spaces.
#' @param islands_path Folder where the `islands_file` is stored
#' @param islands_file Filename for where to store the postcodes and coordinates.
#' @return A data_frame containing postcodes and coordinates.
#'
#' @export
#'
lookup_islands_postcodes = function(islands_postcodes,
islands_path = file.path(options("brclib.data_path"), "Postcodes"),
islands_file = "UK Islands postcodes.csv") {
channel_file = file.path(islands_path, islands_file)
# track existing postcodes already scraped
existing_pc = c()
# load Islands postcodes we previously stored (if it exists)
if (file.exists(channel_file)) {
channel = readr::read_csv(channel_file)
existing_pc = channel$Postcode2
}
# get rid of spaces (just in case not already done)
islands_postcodes = gsub(" ", "", islands_postcodes)
# get postcodes not in our current list
channel_new = tibble::tibble(
Postcode2 = islands_postcodes[!islands_postcodes %in% existing_pc],  # filter out postcodes we've looked up in the past
Longitude = 0.0,
Latitude = 0.0
)
# set user agent
ua = httr::user_agent("https://redcross.org.uk")
# scrape coordinates for each postcode
if (nrow(channel_new) > 0) {  #... only if there are new postcodes to scrape
print("Scraping new postcodes...")
for (i in 1:nrow(channel_new)) {
pc = channel_new$Postcode2[i]
# get webpage data
req = httr::GET(paste0("https://checkmypostcode.uk/", pc), ua)
# load html
out = httr::content(req, "text")
doc = xml2::read_html(out)
# get list of coordinates
coords = doc %>%
rvest::html_nodes(".small") %>%
rvest::html_text()
lat = as.numeric(stringr::str_extract(coords[1], "-?[0-9]+\\.[0-9]+"))
lon = as.numeric(stringr::str_extract(coords[2], "-?[0-9]+\\.[0-9]+"))
channel_new$Longitude[i] = lon
channel_new$Latitude[i]  = lat
Sys.sleep(0.75)  # scrape responsibly
}
} else {
print("No new postcodes to scrape")
}
# add new postcodes and save
if (exists("channel")) {
channel = dplyr::bind_rows(channel, channel_new)
} else {
channel = channel_new
}
readr::write_csv(channel, channel_file)
channel  # return the postcodes
}
# lookup
channel = lookup_islands_postcodes(channel_new$Postcode2)
# merge in Channel Island postcodes
postcodes = postcodes %>%
dplyr::left_join(channel, by = "Postcode2") %>%
dplyr::mutate(Longitude = ifelse(Longitude.x == 0, Longitude.y, Longitude.x),
Latitude  = ifelse(round(Latitude.x, 0) == 100, Latitude.y, Latitude.x)) %>%
dplyr::select(-Longitude.x, -Longitude.y, -Latitude.x, -Latitude.y) %>%
tidyr::replace_na(list(Latitude = 100, Longitude = 0))
##
## merge all postcodes
##
# merge
vols = vols %>%
dplyr::left_join(postcodes, by="Postcode2")
vols$Postcode2 = NULL  # don't need the truncated column anymore
vols$Postcode.y = NULL
vols = dplyr::rename(vols, Postcode = Postcode.x)
##
## Save
##
vols = vols %>%
dplyr::select(-`First Name`, -`Last Name`, -`User Email`, -mobile_number, -date_of_birth, -medical_conditions, -emergency_contact_name, -emergency_contact_relationship, -emergency_contact_number)
vols
library(brclib)
library("brclib", lib.loc="~/R/win-library/3.6")
detach("package:brclib", unload=TRUE)
library(brclib)
devtools::document()
library(brclib)
get_brc_colours()
library(brclib)
